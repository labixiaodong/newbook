# 使用Python+MySql，构建数据处理平台

数据分析有50%的时间是在用SQL写业务部门的数据需求，所以数据分析师经常被人称为「SQL Boy」或者「查数姑」，好在业务部门的数据逻辑是有限的，我们只需要写好特定的脚本，定时发送就好了，以后新增的数据需求都添加到脚本当中，这样来自业务部门的固定需求就会越来越少，我们也就有更多的时间做深入的数据洞察。

用到的技能包括：

- MySQL数据库 + Navicat
- Python pymysql模块
- Python pandas 模块
- Python 邮件处理模块
- Python request/post 模块
- Python pyechart模块

首先来讲一下我们的数据处理流程：

0. 搭建python+mysq连接池

1. 从excel中写入数据到mysql
2. 从mysql当中灵活取数，并使用pandas处理
3. 把数据通过邮件处理模块定时发送给业务方
4. 把数据通过钉钉消息模块定时发送给业务方
5. 数据可视化
6. 脚本自动化运行部署

## 0、连接池是数据处理的根基

为什么说连接池是数据处理的根基呢？首先，数据的「增删改查」都要连接到数据库，如果频繁的连接数据库会给数据库造成非常大的压力，「连接池」的概念可以简单理解为有很多连接的池子，用的时候自动取即可，不会给数据库造成很大的压力。

## 1、数据源导入

我们的数据源，以excel导入为例，可以模拟业务方提供数据的场景，这其中也包含新建mysql表的操作，并且叠加「写入」的操作，在这一部分我们将深入理解mysql写入数据的流程和规范。

## 2、灵活取数

第一步我们已经有了数据了，第二步就按照业务方的需求，把所需数据取出来，这里就会用到mysql「查询」的功能，并且在这一部分将会涵盖大部分日常工作当中用到的函数和方法。

## 3、数据分发

通过第二步取出数据之后，第三步就是发送给业务方，我们有两个渠道「邮件」和「钉钉」，通过这两个渠道我们可以每天/每周/每月定时自动发送数据。

## 4、数据可视化

这一步可以作为附加动作，把数据通过可视化的方式呈现出来，直接通过钉钉发送出去，「逼格」更高。

## 5、自动化脚本的部署

要想要脚本在固定的时间自动运行，需要进行部署操作，有服务器的同学可以跟着我直接上手了，没有服务器的同学也没关系，我为也为大家准备了Windows系统下，部署脚本的流程。

以上大概需要5-6节课的时间更新完成，最终我们以结果为导向，让每位同学都能购在学会的同时，获得一套数据自己的代码。

